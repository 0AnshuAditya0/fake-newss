# ğŸš€ Quick Reference - Caching & Retry System

## ğŸ“ Key URLs

```
Homepage:        http://localhost:3000
Dashboard:       http://localhost:3000/dashboard
Admin Stats:     http://localhost:3000/admin
Stats API:       http://localhost:3000/api/stats
Analyze API:     http://localhost:3000/api/analyze
```

## ğŸ”§ Quick Commands

```bash
# Start development server
npm run dev

# View stats in terminal
curl http://localhost:3000/api/stats | jq

# Test analysis with cache
curl -X POST http://localhost:3000/api/analyze \
  -H "Content-Type: application/json" \
  -d '{"text": "Your test article here..."}'

# Watch stats update
watch -n 1 'curl -s http://localhost:3000/api/stats | jq'
```

## ğŸ“Š Console Log Emojis

```
âœ… Success / Cache HIT
âŒ Failure / Cache MISS
ğŸ¤– HuggingFace API call
ğŸ¯ ML Prediction result
ğŸ’¾ Result cached
ğŸ• Cache expired
ğŸ§¹ Cache cleanup
â³ Waiting for retry
ğŸš« All retries exhausted
âš ï¸ Warning
```

## ğŸ¯ Testing Scenarios

### Test 1: Cache Performance
```javascript
// First request (cache miss)
await fetch('/api/analyze', {
  method: 'POST',
  body: JSON.stringify({ text: 'Test article' })
});
// Response time: ~2-3 seconds

// Second request (cache hit)
await fetch('/api/analyze', {
  method: 'POST',
  body: JSON.stringify({ text: 'Test article' })
});
// Response time: < 50ms âš¡
```

### Test 2: Retry Logic
```bash
# Temporarily set invalid API key
HUGGINGFACE_API_KEY=invalid_key

# Make request - watch console for:
# ğŸ¤– Attempt 1/3 â†’ âŒ Failed â†’ â³ Wait 1s
# ğŸ¤– Attempt 2/3 â†’ âŒ Failed â†’ â³ Wait 2s
# ğŸ¤– Attempt 3/3 â†’ âŒ Failed â†’ ğŸš« Fallback
```

### Test 3: Monitor Stats
```bash
# Open admin dashboard
http://localhost:3000/admin

# Make 10 analyses
# Watch cache hit rate increase
# See stats update in real-time
```

## ğŸ“ˆ Key Metrics

| Metric | Target | Current |
|--------|--------|---------|
| Cache Hit Rate | > 40% | Check `/admin` |
| Response Time (cached) | < 100ms | ~50ms |
| Response Time (uncached) | < 5s | ~2-3s |
| API Failure Rate | < 10% | Check `/admin` |
| Cache Utilization | < 80% | Check `/admin` |

## ğŸ” Response Headers

Every API response includes:
```
X-Cache-Status: HIT | MISS
X-Used-Cache: true | false
X-Processing-Time: 45ms
```

Check in browser DevTools â†’ Network â†’ Response Headers

## ğŸ› ï¸ Configuration Quick Edit

### Increase Cache Size
```typescript
// lib/cache.ts
const MAX_CACHE_SIZE = 500; // Default: 100
```

### Adjust Cache TTL
```typescript
// lib/cache.ts
const CACHE_TTL = 30 * 60 * 1000; // 30 minutes (default: 1 hour)
```

### Change Retry Count
```typescript
// lib/ml-service.ts
await callHuggingFaceWithRetry(text, 5); // Default: 3
```

### Modify Rate Limit
```typescript
// app/api/analyze/route.ts
const RATE_LIMIT = 20; // Default: 10
```

## ğŸ› Debugging

### Check Cache Status
```javascript
// In browser console
fetch('/api/stats')
  .then(r => r.json())
  .then(console.log);
```

### View Console Logs
```bash
# Terminal where npm run dev is running
# Look for emoji indicators:
âœ… Cache HIT
âŒ Cache MISS
ğŸ¤– API attempt
```

### Clear Cache
```javascript
// Currently no endpoint - restart server
# Or add manual clear button in admin dashboard
```

## ğŸ“ Common Issues

### Issue: Cache not working
**Check:**
1. Is server restarted after code changes?
2. Are you sending identical text?
3. Check console for cache logs

### Issue: API still failing
**Check:**
1. Is API key valid? (Check `.env.local`)
2. Is HuggingFace API down? (Check status.huggingface.co)
3. Check console for retry attempts

### Issue: Stats not updating
**Check:**
1. Refresh admin dashboard
2. Make some analyses first
3. Check `/api/stats` endpoint directly

## ğŸ“ Interview Questions & Answers

**Q: How does caching improve performance?**
A: Reduces API calls by 40-60%, response time from 2-3s to < 50ms (60x faster).

**Q: Why exponential backoff?**
A: Prevents overwhelming API during outages, gives time to recover, industry standard.

**Q: How would you scale this?**
A: Migrate to Redis for distributed caching, add CDN layer, implement request queuing.

**Q: What happens if cache is full?**
A: LRU cleanup removes 20% oldest entries automatically.

**Q: How do you monitor performance?**
A: Stats API + Admin dashboard with real-time metrics, response headers for debugging.

## ğŸ“š Documentation Files

```
README.md                    - Main documentation
CACHING_AND_RETRY.md        - Detailed system guide
IMPLEMENTATION_SUMMARY.md   - What was built
QUICK_REFERENCE.md          - This file
SETUP.md                    - Installation guide
API.md                      - API documentation
```

## âœ… Quick Health Check

```bash
# 1. Server running?
curl http://localhost:3000/api/stats

# 2. Cache working?
# Make same request twice, check X-Cache-Status header

# 3. Retry working?
# Set invalid API key, check console logs

# 4. Dashboard accessible?
open http://localhost:3000/admin

# 5. Stats accurate?
# Compare /api/stats with admin dashboard
```

## ğŸš€ Production Checklist

- [ ] Valid HuggingFace API key set
- [ ] Cache size appropriate for traffic
- [ ] Rate limiting configured
- [ ] Monitoring dashboard accessible
- [ ] Error logging enabled
- [ ] Response headers added
- [ ] Documentation updated
- [ ] Tests passing

---

**Everything you need at a glance!** ğŸ“‹
